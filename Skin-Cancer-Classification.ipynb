{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surya/.conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/surya/.conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import Utility\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
    "from scipy.misc import imresize\n",
    "import itertools\n",
    "\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the augmented training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainList = [\"others\",\"Melanoma/original\",\"Melanoma/left_rotate\",\"Melanoma/flip\",\"Melanoma/right_rotate\"]\n",
    "class_id = 0\n",
    "class_path = []\n",
    "segs_path = []\n",
    "classes = []\n",
    "imgs_path = []\n",
    "paths = []\n",
    "Melanoma = []\n",
    "for training_name in trainList:\n",
    "    class_path = Utility.imlist(training_name)\n",
    "    paths += class_path\n",
    "    classes += [class_id] * len(class_path)\n",
    "    class_id += 1\n",
    "    if(class_id>1):\n",
    "        class_id=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the segmented image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"gt\"\n",
    "gt_paths = []\n",
    "for pt in paths:\n",
    "    #print(pt)\n",
    "    newfile = pt.split(\"/\")[-1][0:-4]+ \"_segmentation.png\"\n",
    "    newpath = path+\"/\" + newfile\n",
    "    #print (newpath)\n",
    "    gt_paths.append(newpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data augmentation\n",
    "import shutil\n",
    "for pt in range(0,1626):\n",
    "    shutil.copy(gt_paths[pt],\"GT/non_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melanoma Data is rotated along all the 4 directions \n",
    "path = [\"GT/non_cancer\",\"GT/original\",\"GT/left_rotate\",\"GT/flip\",\"GT/right_rotate\"]\n",
    "gt_paths = []\n",
    "\n",
    "i = 0\n",
    "j = 0 \n",
    "for pt in paths:\n",
    "    #print(pt)\n",
    "    newfile = pt.split(\"/\")[-1][0:-4]+ \"_segmentation.png\"\n",
    "    \n",
    "    if(j==1626 or j == 2000 or j==2374 or j == 2748):\n",
    "        i = i + 1 \n",
    "    j = j + 1    \n",
    "    newpath = path[i] +\"/\" + newfile\n",
    "    \n",
    "    #print (newpath)\n",
    "    gt_paths.append(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_images = []\n",
    "seg_images = []\n",
    "for i in range(len(paths)):\n",
    "    im = cv2.imread(paths[i])\n",
    "    seg = cv2.imread(gt_paths[i],0)\n",
    "    norm_images.append(im)\n",
    "    seg_images.append(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying logical mask to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented = []\n",
    "\n",
    "for i in range(len(norm_images)):\n",
    "    img1 = cv2.resize(norm_images[i], (128,128))\n",
    "    img2 = cv2.resize(seg_images[i], (128,128))\n",
    "    \n",
    "    #print(img1.shape)\n",
    "    #print(img2.shape)\n",
    "    B,G,R = cv2.split(img1)\n",
    "    maskB = np.multiply(B,img2)\n",
    "    maskG = np.multiply(G,img2)\n",
    "    maskR = np.multiply(R,img2)\n",
    "    img = cv2.merge((maskB,maskG,maskR))\n",
    "    segmented.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segemented = np.array(segmented)\n",
    "norm_images = np.array(norm_images)\n",
    "seg_images = np.array(seg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"segemented.npy\",segmented)\n",
    "np.save(\"norm_images.npy\",norm_images)\n",
    "np.save(\"seg_images.npy\",seg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fca621a9dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca6b4bcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(seg_images[0])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(segemented[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_seg = segemented[0:1326]\n",
    "mela_seg = segemented[1626:1950]\n",
    "mela_seg2 = segemented[2000:2324]\n",
    "mela_seg3 = segemented[2374:2698]\n",
    "mela_seg4 = segemented[2748:3072]\n",
    "x_train = np.concatenate((other_seg,mela_seg,mela_seg2,mela_seg3,mela_seg4),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_segt = segemented[1326:1626]\n",
    "mela_segt = segemented[1950:2000]\n",
    "mela_seg2t = segemented[2324:2374]\n",
    "mela_seg3t = segemented[2698:2748]\n",
    "mela_seg4t = segemented[3072:3122]\n",
    "\n",
    "\n",
    "x_test = np.concatenate((other_segt,mela_segt,mela_seg2t,mela_seg3t,mela_seg4t),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128, 128, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((classes[:1326],classes[1626:1950],classes[2000:2324],classes[2374:2698],classes[2748:3072]),axis=0)\n",
    "y_test = np.concatenate((classes[1326:1626],classes[1950:2000],classes[2324:2374],classes[2698:2748],classes[3072:3122]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = LabelEncoder().fit_transform(y_test)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model with 6 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surya/.conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", padding=\"same\", data_format=\"channels_last\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/surya/.conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/surya/.conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", data_format=\"channels_last\")`\n",
      "  del sys.path[0]\n",
      "/home/surya/.conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "Optimizer=Adam(lr=0.001)\n",
    "objective='binary_crossentropy'\n",
    "def center_normalize(x):\n",
    "    return (x-K.mean(x))/K.std(x)\n",
    "model=Sequential()\n",
    "#input layer\n",
    "model.add(Activation(activation=center_normalize, input_shape=(128, 128,3)))\n",
    "# convolutional layer\n",
    "model.add(Convolution2D(32,5,5,border_mode='same',activation='relu',dim_ordering='tf'))\n",
    "#pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2),dim_ordering='tf'))\n",
    "# convolutional layer\n",
    "model.add(Convolution2D(64,3,3,border_mode='same',activation='relu',dim_ordering='tf'))\n",
    "# pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2),dim_ordering='tf'))\n",
    "model.add(Flatten())\n",
    "# Relu \n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Sigmoid Fully connected layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss=objective,optimizer=Optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surya/.conda/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2622/2622 [==============================] - 96s 37ms/step - loss: 0.3208 - acc: 0.8602\n",
      "Epoch 2/20\n",
      "2622/2622 [==============================] - 99s 38ms/step - loss: 0.2349 - acc: 0.9113\n",
      "Epoch 3/20\n",
      "2622/2622 [==============================] - 99s 38ms/step - loss: 0.1670 - acc: 0.9382\n",
      "Epoch 4/20\n",
      "2622/2622 [==============================] - 101s 39ms/step - loss: 0.1042 - acc: 0.9636\n",
      "Epoch 5/20\n",
      "2622/2622 [==============================] - 103s 39ms/step - loss: 0.0653 - acc: 0.9813\n",
      "Epoch 6/20\n",
      "2622/2622 [==============================] - 106s 40ms/step - loss: 0.0451 - acc: 0.9884\n",
      "Epoch 7/20\n",
      "2622/2622 [==============================] - 105s 40ms/step - loss: 0.0219 - acc: 0.9956\n",
      "Epoch 8/20\n",
      "2622/2622 [==============================] - 108s 41ms/step - loss: 0.0150 - acc: 0.9987\n",
      "Epoch 9/20\n",
      "2622/2622 [==============================] - 105s 40ms/step - loss: 0.0081 - acc: 0.9996\n",
      "Epoch 10/20\n",
      "2622/2622 [==============================] - 106s 40ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "2622/2622 [==============================] - 108s 41ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "2622/2622 [==============================] - 106s 41ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "2622/2622 [==============================] - 106s 41ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "2622/2622 [==============================] - 106s 40ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "2622/2622 [==============================] - 108s 41ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "2622/2622 [==============================] - 103s 39ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "2622/2622 [==============================] - 100s 38ms/step - loss: 7.6736e-04 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "2622/2622 [==============================] - 99s 38ms/step - loss: 6.3984e-04 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "2622/2622 [==============================] - 99s 38ms/step - loss: 6.2527e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "2622/2622 [==============================] - 99s 38ms/step - loss: 5.8609e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca54601278>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=50,nb_epoch=20,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "Y_test = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.65      0.68       300\n",
      "          1       0.54      0.61      0.57       200\n",
      "\n",
      "avg / total       0.64      0.63      0.64       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "activation_5 (Activation)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8388736   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 8,409,922\n",
      "Trainable params: 8,409,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
